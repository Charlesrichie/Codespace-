{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPVTh7RAee6vCH7Yh0cTR0k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Recurrent Neural Networks\n","The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems."],"metadata":{"id":"F1wgCAcRnehM"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM\n","from keras.datasets import mnist"],"metadata":{"id":"Q2f5bNLZnFXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test\n","\n","x_train = x_train/255.0\n","x_test = x_test/255.0\n","\n","print(x_train.shape)\n","print(x_train[0].shape)"],"metadata":{"id":"Cxp8wyLonMMT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X63Xhu8tm5OM"},"outputs":[],"source":["model = Sequential()\n","model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n","model.add(Dropout(0.2))\n","\n","model.add(LSTM(128, activation='relu'))\n","model.add(Dropout(0.1))\n","\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(10, activation='softmax'))"]},{"cell_type":"code","source":["from keras.optimizers import adam\n","opt = adam(lr=0.001, decay=1e-6)\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=opt,\n","    metrics=['accuracy'],\n",")\n","\n","model.fit(x_train,\n","          y_train,\n","          epochs=3,\n","          validation_data=(x_test, y_test))"],"metadata":{"id":"yRJWM5dgnV9D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LSTM for Time Series"],"metadata":{"id":"o_fXNIysnxix"}},{"cell_type":"code","source":["import pandas\n","import matplotlib.pyplot as plt\n","dataset = pandas.read_csv('airline-passengers.csv', usecols=[1], engine='python')\n","plt.plot(dataset)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"1QQCEHWTn3wg","executionInfo":{"status":"error","timestamp":1639732075707,"user_tz":-60,"elapsed":45,"user":{"displayName":"Charles Oredola","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnpwCalP23D3Pr8M6WnJ42nMBIpm7KfjhgDPqn=s64","userId":"14286154376090524793"}},"outputId":"48b4a032-8d09-4d7c-9eb9-9b398d53f49e"},"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e1e4c61f5dab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'airline-passengers.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                     \u001b[0;34m'are \"c\", \"python\", or \"python-fwf\")'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 )\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2387\u001b[0m             \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m         )\n\u001b[1;32m   2391\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'airline-passengers.csv'"]}]},{"cell_type":"code","source":["import numpy\n","import matplotlib.pyplot as plt\n","import pandas\n","import math\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error"],"metadata":{"id":"uNef1js-oFcW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the dataset\n","dataframe = pandas.read_csv('airline-passengers.csv', usecols=[1], engine='python')\n","dataset = dataframe.values\n","dataset = dataset.astype('float32')"],"metadata":{"id":"f17FDRp1oUBc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# normalize the dataset\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","dataset = scaler.fit_transform(dataset)"],"metadata":{"id":"PfjiVx4OoZ-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# split into train and test sets\n","train_size = int(len(dataset) * 0.67)\n","test_size = len(dataset) - train_size\n","train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n","print(len(train), len(test))"],"metadata":{"id":"RoPlA9qvoekb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert an array of values into a dataset matrix\n","def create_dataset(dataset, look_back=1):\n","\tdataX, dataY = [], []\n","\tfor i in range(len(dataset)-look_back-1):\n","\t\ta = dataset[i:(i+look_back), 0]\n","\t\tdataX.append(a)\n","\t\tdataY.append(dataset[i + look_back, 0])\n","\treturn numpy.array(dataX), numpy.array(dataY)"],"metadata":{"id":"8izgFyISohd4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reshape into X=t and Y=t+1\n","look_back = 1\n","trainX, trainY = create_dataset(train, look_back)\n","testX, testY = create_dataset(test, look_back)"],"metadata":{"id":"FY3vneuRoqgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reshape input to be [samples, time steps, features]\n","trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n","testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"],"metadata":{"id":"SDuyjnqzoy0j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create and fit the LSTM network\n","model = Sequential()\n","model.add(LSTM(4, input_shape=(1, look_back)))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)"],"metadata":{"id":"xTny36fAoQah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make predictions\n","trainPredict = model.predict(trainX)\n","testPredict = model.predict(testX)\n","# invert predictions\n","trainPredict = scaler.inverse_transform(trainPredict)\n","trainY = scaler.inverse_transform([trainY])\n","testPredict = scaler.inverse_transform(testPredict)\n","testY = scaler.inverse_transform([testY])\n","# calculate root mean squared error\n","trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n","print('Train Score: %.2f RMSE' % (trainScore))\n","testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n","print('Test Score: %.2f RMSE' % (testScore))"],"metadata":{"id":"hs2RlDUUpSUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# shift train predictions for plotting\n","trainPredictPlot = numpy.empty_like(dataset)\n","trainPredictPlot[:, :] = numpy.nan\n","trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n","# shift test predictions for plotting\n","testPredictPlot = numpy.empty_like(dataset)\n","testPredictPlot[:, :] = numpy.nan\n","testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n","# plot baseline and predictions\n","plt.plot(scaler.inverse_transform(dataset))\n","plt.plot(trainPredictPlot)\n","plt.plot(testPredictPlot)\n","plt.show()"],"metadata":{"id":"jLjG9D8vpYyI"},"execution_count":null,"outputs":[]}]}